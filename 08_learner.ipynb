{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math,torch,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from .conv import *\n",
    "except:\n",
    "    from src.miniai.conv import *\n",
    "\n",
    "from fastprogress import progress_bar,master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import torchvision.transforms.functional as TF\n",
    "from contextlib import contextmanager\n",
    "from torch import nn,tensor\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "try:\n",
    "    from .datasets import *\n",
    "    from .conv import *\n",
    "except:\n",
    "    from src.miniai.datasets import *\n",
    "    from src.miniai.conv import *\n",
    "import logging\n",
    "from fastcore.test import test_close\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fashion_mnist (/Users/diegomedina-bernal/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n",
      "100%|██████████| 2/2 [00:00<00:00, 707.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using our dataset from before\n",
    "# we will be using a dataset dictionary from huggingface\n",
    "x, y = 'image', 'label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "tds = dsd.with_transform(transformi) # transformi is an inplace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd['train']['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds['train']['image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoaders:\n",
    "    \"\"\"This class is a wrapper for the dataloaders, it specifically takes in a dataset dictionary from huggingface in this case\"\"\"\n",
    "    def __init__(self, *dls):\n",
    "        self.train, self.valid = dls[:2]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dd(cls, dd, batch_size, num_workers=0, as_tuple=False):\n",
    "        \"\"\"a dd is a dataset dictionary from huggingface. calling values return the dictionary values which are the datasets in the object\"\"\"\n",
    "        return cls(*[DataLoader(ds, batch_size, num_workers=num_workers, collate_fn=collate_dict(ds)) for ds in dd.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders.from_dd(tds, bs, num_workers=4)\n",
    "dt = dls.train\n",
    "xb, yb = next(iter(dt))\n",
    "xb.shape, yb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner:\n",
    "    \"\"\"This is our main class that will be responsible to experimenting and training various models. It serves the purpose of being a vehicle to experiment quickly\"\"\"\n",
    "    def __init__(self, model, dls, loss_func, lr, opt_func=optim.SGD):\n",
    "        \"\"\"\n",
    "        model: <PyTorch Model> the model we are going to train\n",
    "        dls: <Pytorch DataLoader> the dataloaders we are going to use\n",
    "        loss_func: <Callable> the loss function we are going to use\n",
    "        lr: <float> the learning rate we are going to use\n",
    "        opt_func: <PyTorch optimizer (can be custom)> the optimizer we are going to use\n",
    "        \"\"\"\n",
    "        fc.store_attr() # easy method to store all attributes, prevents mistakes\n",
    "\n",
    "    def one_batch(self):\n",
    "        \"\"\"This method is responsible for one batch of training/evaluation\"\"\"\n",
    "        self.xb, self.yb = to_device(self.batch) # move batch to device\n",
    "        self.preds = self.model(self.xb) # get predictions\n",
    "        self.loss = self.loss_func(self.preds, self.yb) # calculate loss\n",
    "        if self.model.training:\n",
    "            self.loss.backward() # calculate gradients\n",
    "            self.opt.step() # update weights\n",
    "            self.opt.zero_grad() # zero gradients\n",
    "        with torch.no_grad(): self.calc_stats() # calculate stats\n",
    "    \n",
    "    def calc_stats(self):\n",
    "        \"\"\"This method is responsible for calculating stats\"\"\"\n",
    "        acc = (self.preds.argmax(dim=1)==self.yb).float().sum() # calculate accuracy\n",
    "        self.accs.append(acc) # append accuracy to list\n",
    "        n = len(self.xb)\n",
    "        self.losses.append(self.loss*n) # append loss to list\n",
    "        self.ns.append(n) # append number of samples to list\n",
    "    \n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train # set model to training mode or evaluation mode\n",
    "        dl = self.dls.train if train else self.dls.valid # get the correct dataloader\n",
    "        for self.num, self.batch in enumerate(dl): \n",
    "            self.one_batch() # call one_batch method, self.batch will be set to the current batch\n",
    "        n = sum(self.ns)\n",
    "        print(f\"Epoch: {self.epoch+1}\", 'train' if self.model.training else 'valid', f\"Loss: {sum(self.losses).item()/n}\", f\"Accuracy: {sum(self.accs).item()/n*100}%\")\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        \"\"\"Very lightweight fit method, this is the highest level to train a model via the Learner object\"\"\"\n",
    "        self.accs, self.losses, self.ns = [], [], []\n",
    "        self.model.to(def_device) # place model on appropriate device TODO: Allow this to be changed via fit calls if necessary\n",
    "        self.opt = self.opt_func(self.model.parameters(), lr=self.lr) # create optimizer\n",
    "        self.n_epochs = n_epochs\n",
    "        for self.epoch in range(n_epochs):\n",
    "            self.one_epoch(True) # training\n",
    "            self.one_epoch(False) # evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a simple model to test\n",
    "m, nh = 28*28, 50\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(m, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 10) # output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train Loss: 0.774168 Accuracy: 72.62166666666666%\n",
      "Epoch: 1 valid Loss: 0.767629 Accuracy: 72.92285714285714%\n"
     ]
    }
   ],
   "source": [
    "# creating our learner to test\n",
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2)\n",
    "learn.fit(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric\n",
    "Our metric class will be responsible for calculating any metrics/calculations for the model for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Metric:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self): self.vals, self.ns = [], [] # reset values and number of samples\n",
    "    def add(self, inp, targ=None, n=1):\n",
    "        \"\"\"\n",
    "        inp: <Tensor> the input tensor\n",
    "        targ: <Tensor> the target tensor\n",
    "        n: <int> the number of samples, the minibatch size is another way to interpret this\n",
    "        \"\"\"\n",
    "        self.last = self.calc(inp, targ) # calculate the metric, this will change based on the metric\n",
    "        self.vals.append(self.last) # append the last metric to the list\n",
    "        self.ns.append(n) # append the number of samples to the list\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"This property is responsible for calculating the value of the metric\n",
    "        It will also normalize the metric by the number of samples returning the average\n",
    "        \"\"\"\n",
    "        ns = tensor(self.ns)\n",
    "        return (tensor(self.vals)*ns).sum()/ns.sum()\n",
    "    def calc(self, inps, targs): return inps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Accuracy(Metric):\n",
    "    def calc(self, inps, targs): return (inps==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "acc.add(tensor([0,1,2,0,1,2]), tensor([0,1,1,2,1,0])) # adding a batch or example\n",
    "acc.add(tensor([1,1,2,0,1]), tensor([0,1,1,2,1])) # adding a batch or example, this contains less values but will still work\n",
    "acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6176)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Metric() # loss can be used as a metric\n",
    "loss.add(0.6, n=32) # adding a batch of 32 examples\n",
    "loss.add(0.9, n=2) # adding a batch of 2 examples\n",
    "loss.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176470588235294"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.6*32 + 0.9*2)/(32+2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish lecture 15 and really go through the code\n",
    "# TODO: Try to implement a custom callback\n",
    "# TODO: Start lecture 16\n",
    "# TODO: Recreate a Learner class with custom callbacks from scratch. This project alone should take a few days\n",
    "# -> For this project try to make a learner that is good with text data -> Implement huggingface transformers for now\n",
    "# This will require learning about different transformer models and how to use them with their individual tokenizers\n",
    "# I should create/test for text classification first, then move on to text generation. The idea here is i'm going to be fine-tuning these bigger models\n",
    "# TODO: Extra: Experiment with optimization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0638b84c441d23f3bf1e5bbb68dbbbae5f508c99744b50e7a508082753ac4090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
