{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle, gzip, math, os, time, shutil, torch, matplotlib as mpl, numpy as np\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from typing import Mapping\n",
    "\n",
    "try:\n",
    "    from .training import *\n",
    "    from .datasets import *\n",
    "except:\n",
    "    from src.miniai.training import *\n",
    "    from src.miniai.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.miniai.export import nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_path = Path('./data/mnist/')\n",
    "os.listdir(mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_split(df):\n",
    "    return df.drop('label', axis=1).values, df['label'].values\n",
    "\n",
    "def train_valid_split(X, y, y_n=10000):\n",
    "    X_train, X_valid = X[:-y_n], X[-y_n:]\n",
    "    y_train, y_valid = y[:-y_n], y[-y_n:]\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "def to_tensor(X, y):\n",
    "    return tensor(X).float()/255., tensor(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping our data\n",
    "df = pd.read_csv(mnist_path/'train.csv')\n",
    "X, y = xy_split(df)\n",
    "X_train, X_valid, y_train, y_valid = train_valid_split(X, y)\n",
    "X_train, y_train = to_tensor(X_train, y_train)\n",
    "X_valid, y_valid = to_tensor(X_valid, y_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = X_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple linear layer\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(m, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broken CNN\n",
    "broken_cnn = nn.Sequential(\n",
    "    nn.Conv2d(1, 30, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(30, 10, kernel_size=3, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning our flat vectors into matrices that resemble the images\n",
    "x_imgs = X_train.view(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grabbing a batch of x_imgs\n",
    "xb = x_imgs[:16,None]\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed through our broken cnn to see the output\n",
    "broken_cnn(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Creating conv function to return a customized conv layer\n",
    "def conv(ni, nf, ks=3, stride=2, act=True):\n",
    "    res = nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now create a simple cnn\n",
    "simple_cnn = nn.Sequential(\n",
    "    conv(1, 4),\n",
    "    conv(4, 8),\n",
    "    conv(8, 16),\n",
    "    conv(16, 16),\n",
    "    conv(16, 10, act=False),\n",
    "    nn.Flatten() # flatten our conv output to feed into a linear layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (4): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (5): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn(xb).shape # this is what we want to perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to check for mac silicon gpu\n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take our vector images and create a dataset for our model to use\n",
    "x_images = X_train.view(-1, 1, 28, 28)\n",
    "x_valid_images = X_valid.view(-1, 1, 28, 28)\n",
    "train_ds, valid_ds = Dataset(x_images, y_train), Dataset(x_valid_images, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# check for device, and add a tensor object or dictionary of tensor objects to that device\n",
    "def_device = \"mps\" if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# def_device = \"cpu\"\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    # Map dictionary values to the device if this format is present\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    # else map the tensor object to device\n",
    "    return type(x)(o.to(device) for o in x)\n",
    "\n",
    "# collate to call on batch grab\n",
    "def collate_device(b): return to_device(default_collate(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can train our simple_cnn\n",
    "from torch import optim\n",
    "\n",
    "bs = 256\n",
    "lr = 0.4\n",
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs, collate_fn=collate_device)\n",
    "opt = optim.SGD(simple_cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6641474186897278 0.7910000008583069\n",
      "1 0.5120913469791413 0.8378999996185302\n",
      "2 0.16024165568351745 0.9474000001907349\n",
      "3 0.13110165576934815 0.9573000002861023\n",
      "4 0.11562569268941879 0.9612000002861023\n"
     ]
    }
   ],
   "source": [
    "loss, acc = fit(\n",
    "    model=simple_cnn.to(def_device),\n",
    "    opt=opt,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10252068943977356 0.9676000005722046\n",
      "1 0.09800325930118561 0.9685000005722046\n",
      "2 0.09126972550153732 0.9692000004768372\n",
      "3 0.09272865797281266 0.9697000005722046\n",
      "4 0.0909618160367012 0.9708000007629395\n"
     ]
    }
   ],
   "source": [
    "# continue training with lower learning rate\n",
    "opt = optim.SGD(simple_cnn.parameters(), lr=lr/4)\n",
    "loss, acc = fit(\n",
    "    model=simple_cnn.to(def_device),\n",
    "    opt=opt,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08805583106279373 0.9701000006675721\n",
      "1 0.08864711799621582 0.9705000005722045\n",
      "2 0.08702481895685196 0.9718000008583069\n",
      "3 0.08783251739740372 0.970700000667572\n",
      "4 0.08711385513544083 0.9715000008583069\n"
     ]
    }
   ],
   "source": [
    "# continue training with lower learning rate\n",
    "opt = optim.SGD(simple_cnn.parameters(), lr=lr/10)\n",
    "loss, acc = fit(\n",
    "    model=simple_cnn.to(def_device),\n",
    "    opt=opt,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (4): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (5): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = simple_cnn[:-1](xb)\n",
    "out = simple_cnn[:-1](xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mnb_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#export'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mnb_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#export\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexported_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcells_2_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexported_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwrite_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/miniai/src/miniai/export.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "nb_export??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export('06_convolutions.ipynb', './src/miniai/conv.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0638b84c441d23f3bf1e5bbb68dbbbae5f508c99744b50e7a508082753ac4090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
